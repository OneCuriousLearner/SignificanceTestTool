#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹å¯¹æ¯”å·¥å…·ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ModelComparisonToolè¿›è¡Œæ¨¡å‹å¯¹æ¯”åˆ†æ
"""

from model_comparison_tool import ModelComparisonTool
import pandas as pd

def example_1_basic_usage():
    """
    ç¤ºä¾‹1: åŸºæœ¬ä½¿ç”¨æ–¹æ³•
    """
    print("=" * 60)
    print("ç¤ºä¾‹1: åŸºæœ¬ä½¿ç”¨æ–¹æ³•")
    print("=" * 60)
    
    # åˆå§‹åŒ–å·¥å…·
    tool = ModelComparisonTool("merged_result-1.csv")
    
    # åŠ è½½æ•°æ®
    df = tool.load_data()
    if df is None:
        return
    
    # è‡ªåŠ¨æ£€æµ‹åˆ†æ•°å­—æ®µ
    score_columns = tool.detect_score_columns(pattern="_score")
    
    # æ¸…ç†æ•°æ®
    score_df = tool.clean_score_data()
    if score_df is None:
        return
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    report = tool.generate_report(score_df, test_type='wilcoxon', alpha=0.05)
    print(report)
    
    # åˆ›å»ºå¯è§†åŒ–
    tool.create_visualization(score_df, save_path="model_comparison_plot.png")

def example_2_custom_columns():
    """
    ç¤ºä¾‹2: è‡ªå®šä¹‰å­—æ®µè®¾ç½®
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹2: è‡ªå®šä¹‰å­—æ®µè®¾ç½®")
    print("=" * 60)
    
    # åˆå§‹åŒ–å·¥å…·
    tool = ModelComparisonTool("Healthbench ç»„åˆ.csv")
    
    # åŠ è½½æ•°æ®
    df = tool.load_data()
    if df is None:
        return
    
    # æ‰‹åŠ¨è®¾ç½®åˆ†æ•°å­—æ®µ
    score_columns = [
        "overall_score-0916",
        "overall_score-0928", 
    ]
    
    model_names = [
        "0916",
        "0928", 
    ]
    
    tool.set_score_columns(score_columns, model_names)
    
    # æ¸…ç†æ•°æ®
    score_df = tool.clean_score_data()
    if score_df is None:
        return
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    report = tool.generate_report(score_df, test_type='wilcoxon', alpha=0.05)
    print(report)

def example_3_baseline_comparison():
    """
    ç¤ºä¾‹3: ä¸åŸºçº¿æ¨¡å‹å¯¹æ¯”
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹3: ä¸åŸºçº¿æ¨¡å‹å¯¹æ¯”")
    print("=" * 60)
    
    # åˆå§‹åŒ–å·¥å…·
    tool = ModelComparisonTool("å½’å› ç»„åˆ.csv")
    
    # åŠ è½½æ•°æ®
    df = tool.load_data()
    if df is None:
        return
    
    # è‡ªåŠ¨æ£€æµ‹åˆ†æ•°å­—æ®µ
    score_columns = tool.detect_score_columns(pattern="åˆ†_")
    
    # æ¸…ç†æ•°æ®
    score_df = tool.clean_score_data()
    if score_df is None:
        return
    
    # é€‰æ‹©åŸºçº¿æ¨¡å‹ï¼ˆå‡è®¾ç¬¬ä¸€ä¸ªæ¨¡å‹ä¸ºåŸºçº¿ï¼‰
    baseline_model = score_columns[0]
    print(f"åŸºçº¿æ¨¡å‹: {baseline_model}")
    
    # ä¸åŸºçº¿æ¨¡å‹å¯¹æ¯”
    baseline_results = tool.baseline_comparison(
        score_df, 
        baseline_model, 
        test_type='wilcoxon', 
        alpha=0.05
    )
    
    print("\nä¸åŸºçº¿æ¨¡å‹å¯¹æ¯”ç»“æœ:")
    print(baseline_results.to_string(index=False))
    
    # æ‰¾å‡ºä¼˜äºåŸºçº¿çš„æ¨¡å‹
    better_models = baseline_results[baseline_results['ä¼˜äºåŸºçº¿'] == True]
    if len(better_models) > 0:
        print(f"\nğŸ‰ å‘ç° {len(better_models)} ä¸ªæ¨¡å‹ä¼˜äºåŸºçº¿:")
        for _, row in better_models.iterrows():
            print(f"  - {row['æ¨¡å‹']}: å‡å€¼å·®å¼‚ = {row['å‡å€¼å·®å¼‚']:.4f}, p = {row['på€¼']:.4f}")
    else:
        print("\nğŸ˜” æ²¡æœ‰æ¨¡å‹æ˜¾è‘—ä¼˜äºåŸºçº¿")

def example_4_different_tests():
    """
    ç¤ºä¾‹4: ä¸åŒç»Ÿè®¡æ£€éªŒæ–¹æ³•å¯¹æ¯”
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹4: ä¸åŒç»Ÿè®¡æ£€éªŒæ–¹æ³•å¯¹æ¯”")
    print("=" * 60)
    
    # åˆå§‹åŒ–å·¥å…·
    tool = ModelComparisonTool("å½’å› ç»„åˆ.csv")
    
    # åŠ è½½æ•°æ®
    df = tool.load_data()
    if df is None:
        return
    
    # è‡ªåŠ¨æ£€æµ‹åˆ†æ•°å­—æ®µ
    score_columns = tool.detect_score_columns(pattern="åˆ†_")
    
    # æ¸…ç†æ•°æ®
    score_df = tool.clean_score_data()
    if score_df is None:
        return
    
    # æµ‹è¯•ä¸åŒçš„ç»Ÿè®¡æ–¹æ³•
    test_methods = ['wilcoxon', 'ttest', 'mannwhitney']
    
    for test_method in test_methods:
        print(f"\nğŸ“Š ä½¿ç”¨ {test_method} æ£€éªŒ:")
        results = tool.pairwise_comparison(score_df, test_type=test_method, alpha=0.05)
        if results is not None and len(results) > 0:
            significant_count = len(results[results['æ˜¯å¦æ˜¾è‘—'] == True])
            print(f"  å‘ç° {significant_count} å¯¹æ¨¡å‹å­˜åœ¨æ˜¾è‘—å·®å¼‚")
            
            # æ˜¾ç¤ºå‰3ä¸ªç»“æœ
            print("  å‰3ä¸ªå¯¹æ¯”ç»“æœ:")
            for i, (_, row) in enumerate(results.head(3).iterrows()):
                print(f"    {i+1}. {row['æ¨¡å‹1']} vs {row['æ¨¡å‹2']}: "
                      f"å·®å¼‚={row['å‡å€¼å·®å¼‚']:.4f}, p={row['på€¼']:.4f}, "
                      f"æ˜¾è‘—={'æ˜¯' if row['æ˜¯å¦æ˜¾è‘—'] else 'å¦'}")

def example_5_advanced_analysis():
    """
    ç¤ºä¾‹5: é«˜çº§åˆ†æåŠŸèƒ½
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹5: é«˜çº§åˆ†æåŠŸèƒ½")
    print("=" * 60)
    
    # åˆå§‹åŒ–å·¥å…·
    tool = ModelComparisonTool("å½’å› ç»„åˆ.csv")
    
    # åŠ è½½æ•°æ®
    df = tool.load_data()
    if df is None:
        return
    
    # è‡ªåŠ¨æ£€æµ‹åˆ†æ•°å­—æ®µ
    score_columns = tool.detect_score_columns(pattern="åˆ†_")
    
    # æ¸…ç†æ•°æ®
    score_df = tool.clean_score_data()
    if score_df is None:
        return
    
    # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    stats_df = tool.calculate_basic_stats(score_df)
    print("ğŸ“ˆ åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯:")
    print(stats_df.to_string(index=False))
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    best_model_idx = stats_df['å‡å€¼'].idxmax()
    best_model = stats_df.loc[best_model_idx, 'æ¨¡å‹']
    best_score = stats_df.loc[best_model_idx, 'å‡å€¼']
    
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model} (å¹³å‡å¾—åˆ†: {best_score:.4f})")
    
    # æ¨¡å‹æ’å
    print("\nğŸ“Š æ¨¡å‹æ’å (æŒ‰å¹³å‡å¾—åˆ†):")
    ranked_models = stats_df.sort_values('å‡å€¼', ascending=False)
    for i, (_, row) in enumerate(ranked_models.iterrows(), 1):
        print(f"  {i}. {row['æ¨¡å‹']}: {row['å‡å€¼']:.4f} Â± {row['æ ‡å‡†å·®']:.4f}")
    
    # åˆ›å»ºè¯¦ç»†çš„å¯è§†åŒ–
    tool.create_visualization(score_df, save_path="detailed_analysis.png")
    print("\nğŸ“Š è¯¦ç»†åˆ†æå›¾è¡¨å·²ä¿å­˜åˆ°: detailed_analysis.png")

def main():
    """
    è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    """
    print("ğŸš€ æ¨¡å‹å¯¹æ¯”å·¥å…·ä½¿ç”¨ç¤ºä¾‹")
    print("æœ¬ç¤ºä¾‹å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ModelComparisonToolè¿›è¡Œæ¨¡å‹å¯¹æ¯”åˆ†æ")
    
    try:
        # è¿è¡Œç¤ºä¾‹1: åŸºæœ¬ä½¿ç”¨
        example_1_basic_usage()
        
        # è¿è¡Œç¤ºä¾‹2: è‡ªå®šä¹‰å­—æ®µ
        example_2_custom_columns()
        
        # è¿è¡Œç¤ºä¾‹3: åŸºçº¿å¯¹æ¯”
        example_3_baseline_comparison()
        
        # è¿è¡Œç¤ºä¾‹4: ä¸åŒæ£€éªŒæ–¹æ³•
        example_4_different_tests()
        
        # è¿è¡Œç¤ºä¾‹5: é«˜çº§åˆ†æ
        example_5_advanced_analysis()
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        print("=" * 60)
        
    except Exception as e:
        print(f"âŒ è¿è¡Œç¤ºä¾‹æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
